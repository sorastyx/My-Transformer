# My-Transformer

This is my own Transformer model for machine translation.It is able to run and inference for some easy translation.

## Quick Start!

### 1,Initialization:

```python
pip install requirements
```

### 2,Training:

```python
cd [what you need to fill]\\transformer源码实现\\pytorch-transformer-main\\pytorch-transformer-main
```

```python
python training.py
```

### 3,Inference:

You can revise the sentence for inference in inference.py

Just change the sentence of the input: ![1772203613079](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\1772203613079.png)

```python
python inference.py
```

### 4，Noted:

I complete this task on a vGPU-32GB cuda. 

Training for one epoch costs about 30s-1min.

I referred to the bilibili video:
https://www.bilibili.com/video/BV1MGrTYVEXq/?spm_id_from=333.1007.top_right_bar_window_default_collection.content.click&vd_source=20df0a25b4d9157b37d387d0de0bb483













